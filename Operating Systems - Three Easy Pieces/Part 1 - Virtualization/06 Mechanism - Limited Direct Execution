[06 Mechanism - Limited Direct Execution]

(6.1 Basic Technique: Limited Direct Execution)
	- "limited direct execution"
		-> OS developers came up with a tehnique (in order to make a program run as fast as one might expect)

	- "direct execution"
		-> just run the program directly on the CPU.
		-> when the OS wishes to start a program running,
			1) it creates a process entry for it in a process list
			2) allocates memory for it
			3) loads the program code into memory (from disk)
			4) locates its entry point (i.e, the main() routine or something similar)
			5) jumpts to it, and starts running the user's code.

(6.2 Problem #1: Restricted Operations)
	- "Direct Execution"
		-> Fast
		-> Runs natively on the hardware CPU and thus executes as quickly as one would expect.

	* What if the process wishes to perform some kind of restricted operation, such as issueing an I/O request to a disk, or gaining access to more system resources such as CPU or memory?
		-> One approach : simply be to let any process do whatever it wants in terms of I/O and other related operations.

		* However, doing so would prevent the construction of many kinds of systems that are desirable.
			ex)
				+ if we wish to build a file system that checks permissions before granting access to a file, we can't simply let any user process issue I/Os to the disk.

				+ a process could simply read or write the entire disk and thus all protections would be lost.

	- "user mode" (new processor mode)
		-> code that runs in user mode is restricted in what it can do.
			ex)
				+ When running in user mode, a process can't issue I/O requests
				* a process can't issue I/O requests
					-> doing so would result in the processor raising an exception; the OS would then likely kill the process.

	- "kernel mode" (contrast to user mode)
		-> code that runs can do what it likes, including privileged operations such as issuing I/O requests and executing all types of restricted instructions.

	- "system call" (in order to perform some kind of privileged operation from user process)

	* to execute a system call, a program must execute a special "trap" instruction.
		-> instruction simultaneously jumps into the kernel and raises the privilege level to kernel mode
		-> once in the kernel, the system can now perform whatever privileged operations are needed, and thus do the required work for the calling process.

		* When finished, the OS calls a special "return-from-trap" instruction
			-> returns into the calling user program while simultaneously reducing the privilege level back to user mode.

	- On x86, the processor will push the program counter, flags, and a few other registers onto a per-process kernel stack.
		-> the return-from-trap will pop these values off the stack and resume execution of the user mode program.

	- Kernel sets up a "trap table" at boot time.
		ex)
			+ when a keyboard interrupt occurs, or when a program makes a system call?
				-> the OS informs the hardware of the locations of these "trap handlers", usually with some kind of special instruction.

				-> Once the hardware is informed, it remembers the location of these handlers until the machine is next rebooted, and thus the hardware knows what to do when system calls and other exceptional events take place.

(6.3 Problem #2: Switching Between Processes)
	- "Cooperative" approach
		-> the OS trusts the processes of the system to behave reasonably.
		-> Processes that run for too long are assumed to periodically give up the CPU so that the OS can decide to run some other task.

	- How does a friendly process give up the CPU in this utopian world?
		1) by making "system calls" frequently
			ex)
				+ to open a file and subsequently read it, or to send a message to another machine, or to create a new process.

			-> often include an explicit "yield"
				-> which does nothing except to transfer control to the OS so it can run other processes.

		2) Applications also transfer control to the OS when they do something illegal.
			ex)
				+ if an application divides by zero, or tries to access memory that it shouldn't be able to access
					-> it will generate a "trap" to the OS.

					-> The OS will have control of the CPU again (And likely terminate the offending process)

	* In a "cooperative scheduling system", the OS regains control of the CPU by waiting for a system call or an illegal operation of some kind to take place.

	- "reboot the machine"
		-> when the OS can't do much at all when a process refuses to make system calls (or mistakes) and thus return control to the OS.

		-> in the cooperative approach, your only recourse when a process gets stuck in an infinite loop is to resort to the age-old solution to all problems in computer systems.

	<How to gain control without cooperation?>
		- "timer interrupt"
			-> timer device can be programmed to raise an interrupt every so many milliseconds
			-> when the interrupt is raised, the currently running process is halted.
			-> and a pre-configured "interrupt handler" in the OS runs.
			-> OS regains control of the CPU, and thus can do what it please: stop the current process, and start a different one.

		1) OS must inform the hardware of which code to run when the timer interrupt occurs; thus, at boot time.

		2) during the boot sequence, the OS must start the timer, which is of course a privileged operation.

		3) Once the timer has begun, the OS can thus feel safe in that control will eventually be returned to it, and thus the OS is free to run user programs.

		4) The timer can also be turned off (Also a privileged operation).

	<Saving and Restoring Context>
		- Decision made by a part of the operating system known as the "scheduler"
			-> whether to continue running the currently-running process, or switch to a different one.

		- If the decision is made to switch, the OS then executes a low-level piece of code which we refer to as a "context switch".

		- "Context Switch"
			-> all the OS has to do is save a few register values for the currently-executing process (onto its kernel stack, for example)

			-> and restore a few for the soon-to-be-executing process (from its kernel stack).

			-> By doing so, the OS thus ensures that when the return-from-trap instruction is finally executed, instead of returning to the process that was running, the system resumes execution of another process.

		* To save the context of the currently-running process
			-> The OS will execute some low-level assembly code to save the general purpose registers, PC, as well as the kernel stack pointer of the currently-running process, and then restore said regsiters, PC, and switch to the kernel stack for the soon-to-be-executing process.

			-> By switching stacks, the kernel enters the call to the switch code in the context of one process(interrupted) and returns in the context of another(soon-to-be-executing one).

			-> When the OS then finally executes a return-from-trap instruction, the soon-to-be-executing process becomes the currently-running process. (context switch is complete)

		- interrupted by the timer interrupt
			-> hardware saves its registers (onto its kernel stack)
			-> enters the kernel (Switching to kernel mode).
			-> In the timer handler, OS decides to switch from running Process A to Process B.
			-> calls the "switch()" routine, which carefully saves current register values, restores the registers of Process B, and then "switches contexts"
			-> by changing the stack pointer to use another process's kernel stack.
			-> OS returns from-trap, which restores another process's registers and starts running it.

		* two types of register saves/restores during this protocol.
			1) when the timer interrupt occurs; in this case, the "user registers" of the running process are implicitly saved by the hardware using the kernel stack of that process.

			2) when the OS decides to switch from A to B; in this case, the "kernel registers" are explicitly saved by the software, but this time into memory in the process structure of the process.

(6.4. Worried About Conccurency?)
	- OS might "disable interrupts" during interrupt processing
		-> doing so ensures that when one interrupt is being handled, no other one will be delivered to the CPU.

	- OS also developed a number of sophisticated "locking" schemes to protect concurrent access to internal data structures.



