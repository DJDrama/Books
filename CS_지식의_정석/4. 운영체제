[운영체제]
	- CPU 스케줄링
	- 프로세스 관리
	- 메모리 관리
	- 디스크 파일 관리
	- I/O 디바이스 관리

	- 인터럽트: 어떤 신호가 들어왔을 때 CPU를 잠깐 정지시키는 것
		- 마우스, 키보드 등 IO 디바이스로 인한 인터럽트
		- 0으로 숫자를 나누는 산술 연산에서의 인터럽트
		- 프로세스 오류 등

	- 하드웨어 인터럽트 : IO 디바이스에서 발생하는 인터럽트
	- 소프트웨어 인터럽트 : 트랩(trap)이라고도 함. 프로세스 오류 등으로 프로세스가 시스템콜을 호출할 때 발동하는 인터럽트

	- 시스템콜
		- 운영체제가 커널에 접근하기 위한 인터페이스
		- 유저 프로그램이 운영체제의 서비스를 받기 위해 커널 함수를 호출할 때 쓰임.
		- 유저 프로그램이 I/O 요청을 위한 트랩을 발동했다고 하면 다음과 같은 과정이 발생
			1. 유저 프로그램이 I/O 요청 트랩발동
			2. 올바른 I/O 요청인지 확인한 후
			3. 유저 모드가 시스템 콜을 통해
			4. 커널 모드로 변환한 후 커널함수로 실행
		- 커널함수
			- 커널 안에 있는 여러개의 함수(native function이라고도 함)
			- 커널: 운영체제의 핵심 부분, 시스템콜을 제공하며 보안, 메모리, 프로세스, 파일 시스템, I/O 디바이스, I/O 요청 관리 등 운영체제의 중추적인 역할을 함.
		- 유저모드
			- 유저가 접근할 수 있는 영역을 제한적으로 두며 컴퓨터 자원에 함부로 침범하지 못하는 모드
		- 커널모드
			- 모든 컴퓨터 자원에 접근할 수 있는 모드

		- 시스템 콜의 장점
			- 유저 프로그램은 복잡한 파일 시스템과 프로세스 생성 등에 대한 내부 동작을 신경쓸 필요가 없음.
				-> 시스템의 안전성과 보안이 강화됨.
			- 유저 모드에서 시스템 콜로만 커널 모드에 진입할 수 있게 하나의 통로만을 만든 것.
		- modebit
			- 시스템 콜이 작동될 때 modebit을 기반으로 유저 모드와 커널 모드를 구분.
			- 1 또는 0의 값을 가지는 플래그 변수. 1: 유저모드 / 0: 커널모드

	- 메모리계층
		- 레지스터, 캐시, 메모리, 저장장치로 구성
			- 레지스터: CPU안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적음.
			- 캐시 : L1, L2 캐시를 지칭. 휘발성, 속도 빠름, 기억 용량이 적음.
			- 주기억장치: RAM을 가리킴. 휘발성, 속도 빠름, 기억 용량이 보통.
			- 보조기억장치: HDD, SDD를 일컬으며 비휘발성, 속도 낮음, 기억 용량이 많음.

	- 가상메모리와 스와핑, 페이지폴트 그리고 스레싱
		- OS에서 사용되는 메모리 관리 기술.
		- 컴퓨터의 물리적 메모리 부족을 보완하고 RAM에서 디스크 스토리지로 데이터를 일시적으로 전송하는 스와핑을 할 수 있게 하여 컴퓨터가 보조 메모리를 주 메모리인 것처럼 처리 가능.

		- 가상 메모리의 주요한 기능
			1. 주기억장치의 효율적 관리(스와핑)
				- 하드디스크를 주기억장치에 대한 캐시로 설정
				- 당장 사용하는 영역만 유지하고 쓰지 않는 데이터는 하드디스크로 옮긴 뒤, 필요할 때만 렘에 데이터를 불러와 올리고 다시 사용하지 않으면 하드디스크로 내림으로써 램을 효과적으로 관리.
			2. 메모리 관리의 단순화
				- 각 프로세스마다 가상메모리의 통일된 주소 공간 배정 가능 -> 메모리 관리 단순해짐
			3. 메모리 용량 및 안정성 보장
				- 무한한 가상메모리 공간을 배정함으로써 프로세스들끼리 메모리 침범이 일어날 여지를 크게 줄임.

		- 스와핑
			- 페이지 폴트가 발생한 경우 메모리의 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 '마치 메모리처럼' 불러와 쓰는 것.

		- 페이지 폴트
			- 프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우 발생하는 것.

		- 스레싱
			- 메모리의 페이지 폴트율이 높은 것을 의미함.

	- 프로그램과 프로세스 그리고 스레드의 차이
		- 프로세스 : 컴퓨터에서 실행되고 있는 프로그램
		- 스레드 프로세스 : 하나의 스레드만 가지고 있는
		- 멀티스레드 프로세스: 여러 개의 스레드를 가지고 있는 프로세스
		- 스레드는 프로세스 내 작업의 흐름을 지칭.

		- 스레드는 프로세스 내의 스택 메모리 영역을 제외한 다른 메모리 영역을 공유.
		- 프로세스 간의 통신은 IPC를 사용해야 함.
		- 스레드는 메모리를 공유하므로 다른 스레드와의 정보공유가 쉬움.
			-> 그러나 한 스레드의 문제가 생기면 다른 스레드에도 영향을 끼쳐 프로세스에 영향을 줄 수 있음.

	- 프로세스의 메모리 구조
		- 위에서부터 스택, 힙, 데이터 영역(BSS), 코드 영역
			- 스택: 지역변수, 매개변수, 함수가 저장되고 컴파일 시에 크기가 결정되며 '동적'인 특징
			- 힙: 동적 할당할 때 사용되며 런타임 시 크기가 결정됨.
			- 데이터 영역: 전역변수, 정적변수가 저장되고, 정적인 특징.
				- Bss 영역 : 초기화 되지 않은 변수가 0으로 초기화되어 저장됨
				- Data 영역 : 0이 아닌 다른 값으로 할당된 변수들이 저장됨.
			- 코드 영역 : 소스코드 들어감. 정적인 특징

	- PCB와 컨텍스트 스위칭
		- Process Control Block
			- 운영체제에서 프로세스에 대한 메타데이터를 저장한 '데이터'
			- 컨텍스트 스위칭: PCB를 교환하는 과정.

	- 멀티프로세싱과 멀티스레딩, 그리고 IPC
		- 멀티프로세싱: 여러개의 프로세스를 통해 두 가지 이상의 일을 수행할 수 있는 것.
			- 특정 프로세스의 메모리, 프로세스 중 일부가 문제가 발생되더라도 다른 프로세스를 이용해서 처리할 수 있으므로 신뢰성이 높음

		- 멀티스레딩: 프로세스 내 작업을 멀티스레드로 처리하는 기법. 스레드끼리 서로 자원을 공유하기 때문에 효율성이 높음
			- 동시성에도 큰 장점.
			- 한 스레드 문제가 생기면 다른 스레드에도 영향을 끼쳐 스레드로 이루어져 있는 프로세스에 영향을 줄 수 있음.

		- IPC: 프로세스끼리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘.
			- 클라이언트는 데이터를 요청하고 서버는 클라이언트 요청에 응답하는 것도 포함.

	- 공유자원과 임계 영역, 그리고 경쟁상태
		- 공유 자원: 시스템 안에서 각 프로세스, 스레드가 함께 접근할 수 있는 모니터, 프린터, 메모리, 파일, 데이터 등의 자원이나 변수 등

		- 경쟁 상태: 공유 자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황. 동시 접근 시 타이밍이나 순서 등이 결괏값에 영향을 줄 수 있음.

		- 임계 영역: 둘 이상의 프로세스 또는 스레드가 공유 자원에 접근할 때 순서 등의 이유로 결과가 달라지는 코드 영역.

	- 세마포어, 뮤텍스, 모니터의 차이 그리고 교착상태
		- 임계 영역 해결을 위한 방법(뮤텍스, 세마포어, 모니터)
		(조건)
			1. 상호배제: 한 프로세스가 임계 영역에 들어갔을 때 다른 프로세스는 들어갈 수 없음
			2. 한정 대기: 특정 프로세스가 영원히 임계 영역에 들어가지 못하면 안 됨
			3. 융통성 : 한 프로세스가 다른 프로세스의 일을 방해해서는 안 됨

		- 뮤텍스: 스레드가 공유 자원을 lock()을 통해 잠금 설정하고 사용한 후에 unlock()을 통해 잠금해제하는 객체
			- 잠금 및 잠금해제 상태만을 가짐.

		- 세마포어: 일반화된 뮤텍스.
			- 간단한 정수 값과 두 가지 함수 wait(P 함수) 및 signal(V 함수)로 공유 자원에 대한 접근을 처리

		- 모니터: 둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유자원을 숨기고 해당 접근에 대해 인터페이스만 제공하는 객체

		(모니터와 세마포어 차이)
			- 모니터는 세마포어보다 구현이 쉬움
			- 모니터에서 상호 배제는 자동 <-> 세마포어에서는 상호 배제를 명시적으로 구현해야 함.

		- 교착상태 : 두 개 이상의 프로세스들으 서로가 가진 자원을 기다리며 중단된 상태

- CPU 스케줄링과 알고리즘
	- 스케줄링 알고리즘: CPU가 어떤 프로세스를 선택할 것인지
		- CPU 사용률, 처리량(단위 시간당 작업을 마친 프로세스의 수)이 높을수록 대기시간(작업을 요청한 프로세스가 작업을 시작하기 전 대기하는 시간), 응답시간이 짧을수록 좋음.

	- 비선점형 방식 : 프로세스가 스스로 CPU 소유권을 포기하는 방식, 강제로 프로세스를 중지하지 않음.
		-> 컨텍스트 스위칭으로 인한 부하가 적다.

		1. FCFS
			- First Come First Served
			- 가장 먼저 온 것을 가장 먼저 처리하는 알고리즘.
			* 단점: 길게 수행되는 프로세스 때문에 '준비 큐에서 오래 기자리는 현상(convoy effect)'이 발생
		2. SJF
			- Shortest Job First
			- 실행 시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘.
			* 긴 시간을 가진 프로세스가 실행되지 않는 현상(Starvation), 평균 대기 시간이 가장 짧음(실행 시간이 짧은 프로세스 우선 실행하므로)
			* aging: 우선순위를 높이는 방법(이를 통해 우선순위를 높여 starvation을 해결할 수 있음)

	- 선점형 방식 : 현대 운영체제가 쓰는 방식으로 지금 사용하고 있는 프로세스를 알고리즘에 의해 중단시켜 버리고 강제로 다른 프로세스에 CPU 소유권을 할당하는 방식.

		1. 라운드 로빈
			- 각 프로세스는 동일한 할당 시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐(Ready Queue)의 뒤로 가는 알고리즘.
			- 할당 시간이 너무 크면 FCFS가 되고 짧으면 컨텍스트 스위칭이 잦아져서 오버헤드, 비용이 커짐.
			- 전체 작업 시간은 길어지지만 평균 응답 시간은 짧아진다는 특징
			- 로드밸런서에서 트래픽 분산 알고리즘으로도 사용됨.

		2. SRF
			- 중간에 더 짧은 작업이 들어오면 수행하던 프로세스를 중지하고 해당 프로세스를 수행하는 알고리즘. (SJF는 기존 짧은 작업을 모두 수행하고 그 다음 짧은 작업을 이어나감)

		3. 다단계 큐
			- 우선순위에 따른 준비 큐를 여러 개 사용, 큐마다 라운드 로빈이나 FCFS 등 다른 스케줄링 알고리즘을 적용한 것.
			- 큐 간의 프로세스 이동이 안 되므로 스케줄링 부담이 적지면 유연성은 떨어지는 특징.
			- 우선순위가 높은 큐부터 처리되므로 낮은 큐의 프로세스가 처리가 안되는 기아현상(starvation)이 발생할 수도 있음.

	- 캐시, 캐시히트, 캐시미스와 캐시 사례
		- 캐시: 데이터를 미리 복사해 놓는 임시 저장소, 빠른 장치와 느린 장치에서 속도 차이에 따른 병목현상을 줄이기 위한 메모리.
		- 캐시히트: 캐시에서 원하는 데이터를 찾았다면 캐시히트
		- 캐시미스: 데이터가 캐시에 없으면 주 메모리로 가서 데이터를 찾아오는 것

	- 메모리 할당: 고정분할과 가변분할 (연속 할당)
		- 메모리에 '연속적으로' 공간을 할당하는 것
			- 고정분할: 메모리를 미리 나누어 관리(내부 단편화)
			- 가변분할: 매시점 프로그램에 맞춰 동적으로(외부 단편화)

	- 메모리 할당: 페이징, 세그멘테이션, 페이지드 세그멘테이션 (불연속 할당)
		- 불연속 할당: 메모리를 연속적으로 할당하지 않는 기법
			
			- 페이징(paging): 동일한 크기(4kb)의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당. 홀의 크기가 균일하지 않은 문제가 사라지지만 주소 변환이 복잡해짐.
			
			- 세그멘테이션: 페이지 단위가 아닌 세그먼트(segment)로 나누는 방식. 프로세스는 코드, 데이터, 스택, 힙 등으로 이루어지는데, 코드와 데이터 등 이를 기반으로 나눌 수도 있으며 함수 단위로 나눌 수도 있음.
				- 공유와 보안 측면에서 좋으며 홀 크기가 균일하지 않은 문제가 발생.

			- 페이지드 세그멘테이션: 공유나 보안을 의미 단위의 세그먼트로 나누고, 물리적 메모리는 페이지로 나누는 것.

	- 캐시매핑(직접매핑, 연관매핑, 집합-연관매핑)
		* 캐시의 크기는 메모리보다 작기 때문에 항상 메모리의 일부 페이지만을 가지고 있음.

		1. 직접매핑
			- 메모리의 특정 블록은 특정 캐시 라인에만 매핑할 수 있는 것.
			- 메모리가 1~100, 캐시가 1~10이면 1:1~10, 2:2~10, ... 이런 식으로 매핑하는 것.
			* 처리가 빠르지만 충돌 발생이 잦음.

		2. 연관매핑
			- 순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑하여 메모리의 컨텐츠가 캐시의 어느 위치에도 올라갈 수 있는 방법.
			- 충돌이 적지만 캐시의 모든 블록을 탐색해야 해서 속도가 느림. (연관 매핑은 직접 매핑보다 느림)

		3. 집합 연관매핑(Set Associative Mapping)
			- 집합을 나누고 각 집합에 직접 매핑을 사용하는 것.
			- 집합으로 나누었기에 스와핑을 완화시키고, 집합 내의 집합매핑을 사용할 수 있기 때문에 연관매핑처럼 모든 캐시를 뒤지는 일 없이 바로 캐시 히트, 미스 여부를 알 수 있음.

	- 페이지 교체 알고리즘
		1. FIFO(First in First Out): 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법
		2. LRU(Least Recently Used): 참조가 가장 오래된 페이지를 바꾸는 방법
		3. NUR(Not Used Recently): 클록 알고리즘(0과 1을 가진 비트를 둠)
			- 1: 최근에 참조됨
			- 0: 참조되지 않음
			- 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체, 해당 부분을 1로 바꾸는 알고리즘
		4. LFU(Least Frequently Used) : 가장 참조 횟수가 적은 페이지를 교체하는 알고리즘









